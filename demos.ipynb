{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'Hello there',\n",
    "    'How are you?',\n",
    "    'Hello! Hello!',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x5 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1, 0],\n",
       "       [1, 0, 1, 0, 1],\n",
       "       [0, 2, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['are', 'hello', 'how', 'there', 'you']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(['Are you doing fine?']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = 'I have a cat.'\n",
    "doc2 = \"I doesn't have a cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'have', 'a', 'cat', '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'does', \"n't\", 'have', 'a', 'cat']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp('I have a cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I have a cat"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'have', 'a', 'cat']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.text for w in doc1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-PRON-', 'have', 'a', 'cat']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.lemma_ for w in doc1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(\"I doesn't have a cat :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'does', \"n't\", 'have', 'a', 'cat', ':(']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.text for w in doc2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-PRON-', 'do', 'not', 'have', 'a', 'cat', ':(']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.lemma_ for w in doc2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp('I have a dog')\n",
    "doc2 = nlp('I have a cat')\n",
    "doc3 = nlp('I have a banana')\n",
    "doc4 = nlp('Congress voted to reopen the government')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dog"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "banana"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc3[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80168545"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1[3].similarity(doc2[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24327643"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1[3].similarity(doc3[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9681672529980867"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1.similarity(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8753348768953094"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1.similarity(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5484653936168645"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1.similarity(doc4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile accepts the optimizer and the loss function\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "data = np.random.random((1000, 100)).astype(np.float32)\n",
    "labels = np.random.randint(2, size=(1000, 1)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0888392 , 0.52575684, 0.10466124, 0.096262  , 0.76197904,\n",
       "        0.258842  , 0.63712853, 0.6515475 , 0.75484097, 0.84816116,\n",
       "        0.6647068 , 0.91870683, 0.04878277, 0.13528776, 0.9946589 ,\n",
       "        0.4604639 , 0.36947763, 0.196974  , 0.3097918 , 0.36896285,\n",
       "        0.7101364 , 0.6462675 , 0.4810477 , 0.753921  , 0.03047181,\n",
       "        0.2926624 , 0.03936019, 0.8873632 , 0.17017573, 0.71794784,\n",
       "        0.95668125, 0.00934531, 0.46481675, 0.73416185, 0.11787887,\n",
       "        0.34529576, 0.8840936 , 0.18120424, 0.7227192 , 0.7121059 ,\n",
       "        0.2659569 , 0.86615205, 0.80185765, 0.71790755, 0.99298185,\n",
       "        0.1982901 , 0.64232624, 0.29049882, 0.49908778, 0.5950033 ,\n",
       "        0.42488784, 0.9648391 , 0.4178199 , 0.70975584, 0.16018994,\n",
       "        0.69761485, 0.1611004 , 0.35617313, 0.8770781 , 0.9502502 ,\n",
       "        0.30667582, 0.63330185, 0.53394866, 0.8001217 , 0.7815321 ,\n",
       "        0.1878482 , 0.6871309 , 0.04023051, 0.95712036, 0.46058342,\n",
       "        0.92053294, 0.8512616 , 0.06702872, 0.85360605, 0.28098783,\n",
       "        0.18938726, 0.19749293, 0.8678502 , 0.9286143 , 0.29026026,\n",
       "        0.2869731 , 0.27542827, 0.40222773, 0.06344748, 0.082164  ,\n",
       "        0.82821786, 0.91413903, 0.17342064, 0.22417483, 0.03924868,\n",
       "        0.88422656, 0.4481774 , 0.7855454 , 0.3491819 , 0.4003117 ,\n",
       "        0.23879819, 0.33158782, 0.7990248 , 0.6880956 , 0.41771564]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:3 :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7054 - acc: 0.5040\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 102us/step - loss: 0.6949 - acc: 0.5220\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 128us/step - loss: 0.6868 - acc: 0.5550\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 100us/step - loss: 0.6821 - acc: 0.5530\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 0.6780 - acc: 0.5680\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.6747 - acc: 0.5690\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.6711 - acc: 0.5950\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.6684 - acc: 0.6040\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 100us/step - loss: 0.6628 - acc: 0.6140\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 128us/step - loss: 0.6583 - acc: 0.6250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f99af0e82b0>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(3.0, dtype=tf.float32)\n",
    "b = tf.constant(4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_10:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.0, 4.0]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([a,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_2:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(adder, {a: 3, b:4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(adder, {a: 10, b:20})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The same model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(tf.float32, shape=(None, 100))\n",
    "targets = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "\n",
    "fc1 = tf.layers.dense(inputs, 32, activation=tf.nn.relu)\n",
    "outputs = tf.layers.dense(fc1, 1, activation=None)\n",
    "\n",
    "outputs_sigmoid = tf.nn.sigmoid(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder_14:0' shape=(?, 100) dtype=float32>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_12/Relu:0' shape=(?, 32) dtype=float32>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_13/BiasAdd:0' shape=(?, 1) dtype=float32>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.sigmoid_cross_entropy(targets, outputs)\n",
    "accuracy = tf.reduce_mean(tf.to_float(tf.equal(targets, tf.to_float(outputs_sigmoid > 0.5))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(0.001)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.725, accuracy: 0.471\n",
      "Epoch: 1, loss: 0.682, accuracy: 0.509\n",
      "Epoch: 2, loss: 0.693, accuracy: 0.528\n",
      "Epoch: 3, loss: 0.683, accuracy: 0.546\n",
      "Epoch: 4, loss: 0.683, accuracy: 0.557\n",
      "Epoch: 5, loss: 0.678, accuracy: 0.566\n",
      "Epoch: 6, loss: 0.678, accuracy: 0.578\n",
      "Epoch: 7, loss: 0.675, accuracy: 0.582\n",
      "Epoch: 8, loss: 0.674, accuracy: 0.584\n",
      "Epoch: 9, loss: 0.671, accuracy: 0.593\n",
      "Epoch: 10, loss: 0.669, accuracy: 0.599\n",
      "Epoch: 11, loss: 0.668, accuracy: 0.602\n",
      "Epoch: 12, loss: 0.665, accuracy: 0.614\n",
      "Epoch: 13, loss: 0.663, accuracy: 0.607\n",
      "Epoch: 14, loss: 0.661, accuracy: 0.615\n",
      "Epoch: 15, loss: 0.660, accuracy: 0.624\n",
      "Epoch: 16, loss: 0.657, accuracy: 0.632\n",
      "Epoch: 17, loss: 0.656, accuracy: 0.639\n",
      "Epoch: 18, loss: 0.654, accuracy: 0.643\n",
      "Epoch: 19, loss: 0.652, accuracy: 0.657\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "batch_size = 64\n",
    "nb_batches = len(data) // batch_size\n",
    "for epoch in range(nb_epochs):\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    for batch_idx in range(nb_batches):\n",
    "        batch_start = batch_idx * batch_size\n",
    "        batch_end = batch_start + batch_size\n",
    "\n",
    "        batch_inputs = data[batch_start:batch_end]\n",
    "        batch_targets = labels[batch_start:batch_end]       \n",
    "      \n",
    "        _, loss_value, accuracy_value = sess.run(\n",
    "            [train, loss, accuracy], {inputs: batch_inputs, targets: batch_targets}\n",
    "        )\n",
    "        losses.append(loss_value)        \n",
    "        accuracies.append(accuracy_value)\n",
    "        \n",
    "    accuracy_value = np.mean(accuracies)\n",
    "    loss_value = np.mean(loss_value)    \n",
    "    print(f'Epoch: {epoch}, loss: {loss_value:.3f}, accuracy: {accuracy_value:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there's also a `tf.estimator` API that makes the training a little bit simplier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       "[torch.FloatTensor of size 5]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 11\n",
       " 11\n",
       " 11\n",
       " 11\n",
       " 11\n",
       "[torch.FloatTensor of size 5]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The same model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(100, hidden_size)\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        hidden = F.relu(self.fc1(inputs))\n",
    "        outputs = self.fc2(hidden)\n",
    "        \n",
    "        outputs = outputs\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(input_size=data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=100, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.0417\n",
       "-0.1653\n",
       " 0.0369\n",
       "-0.0224\n",
       "[torch.FloatTensor of size (4,1)]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(Variable(torch.rand(4, 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.TensorDataset(torch.from_numpy(data), torch.from_numpy(labels))\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0888\n",
       " 0.5258\n",
       " 0.1047\n",
       " 0.0963\n",
       " 0.7620\n",
       " 0.2588\n",
       " 0.6371\n",
       " 0.6515\n",
       " 0.7548\n",
       " 0.8482\n",
       "[torch.FloatTensor of size 10]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.696, accuracy: 0.493\n",
      "Epoch: 1, loss: 0.695, accuracy: 0.513\n",
      "Epoch: 2, loss: 0.690, accuracy: 0.553\n",
      "Epoch: 3, loss: 0.688, accuracy: 0.562\n",
      "Epoch: 4, loss: 0.687, accuracy: 0.580\n",
      "Epoch: 5, loss: 0.687, accuracy: 0.529\n",
      "Epoch: 6, loss: 0.685, accuracy: 0.564\n",
      "Epoch: 7, loss: 0.685, accuracy: 0.523\n",
      "Epoch: 8, loss: 0.684, accuracy: 0.560\n",
      "Epoch: 9, loss: 0.679, accuracy: 0.600\n",
      "Epoch: 10, loss: 0.677, accuracy: 0.589\n",
      "Epoch: 11, loss: 0.675, accuracy: 0.624\n",
      "Epoch: 12, loss: 0.672, accuracy: 0.623\n",
      "Epoch: 13, loss: 0.669, accuracy: 0.642\n",
      "Epoch: 14, loss: 0.667, accuracy: 0.636\n",
      "Epoch: 15, loss: 0.665, accuracy: 0.648\n",
      "Epoch: 16, loss: 0.662, accuracy: 0.650\n",
      "Epoch: 17, loss: 0.658, accuracy: 0.645\n",
      "Epoch: 18, loss: 0.656, accuracy: 0.647\n",
      "Epoch: 19, loss: 0.655, accuracy: 0.642\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "batch_size = 64\n",
    "nb_batches = len(data) // batch_size\n",
    "for epoch in range(nb_epochs):\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    for i, (inputs, targets) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        inputs = Variable(inputs).cuda()\n",
    "        targets = Variable(targets).cuda()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "\n",
    "        y_pred = (F.sigmoid(outputs) > 0.5).data.cpu().numpy()\n",
    "        y_true = targets.data.cpu().numpy()\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        \n",
    "        losses.append(float(loss))\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "    accuracy = np.mean(accuracies)\n",
    "    loss = np.mean(losses)    \n",
    "    print(f'Epoch: {epoch}, loss: {loss:.3f}, accuracy: {accuracy:.3f}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
