{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'Hello there',\n",
    "    'How are you?',\n",
    "    'Hello! Hello!',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['are', 'hello', 'how', 'there', 'you']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3x5 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1, 0],\n",
       "       [1, 0, 1, 0, 1],\n",
       "       [0, 2, 0, 0, 0]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(['Are you doing fine?']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There are many parameters in `CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'Hello there',\n",
    "    'How are you?',\n",
    "    'Hello! Hello!',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=2,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hello']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [0],\n",
       "       [2]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = 'I have a cat.'\n",
    "doc2 = \"I doesn't have a cat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'have', 'a', 'cat', '.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(doc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'does', \"n't\", 'have', 'a', 'cat']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(doc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp('I have a cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I have a cat"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "have"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'have', 'a', 'cat']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.text for w in doc1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-PRON-', 'have', 'a', 'cat']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.lemma_ for w in doc1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(\"I doesn't have a cat :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'does', \"n't\", 'have', 'a', 'cat', ':(']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.text for w in doc2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-PRON-', 'do', 'not', 'have', 'a', 'cat', ':(']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w.lemma_ for w in doc2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp('I have a dog')\n",
    "doc2 = nlp('I have a cat')\n",
    "doc3 = nlp('I have a banana')\n",
    "doc4 = nlp('Congress voted to reopen the government')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dog"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cat"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "banana"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc3[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc3[3].vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.0228e-01, -7.6618e-02,  3.7032e-01,  3.2845e-02, -4.1957e-01,\n",
       "        7.2069e-02, -3.7476e-01,  5.7460e-02, -1.2401e-02,  5.2949e-01,\n",
       "       -5.2380e-01, -1.9771e-01, -3.4147e-01,  5.3317e-01, -2.5331e-02,\n",
       "        1.7380e-01,  1.6772e-01,  8.3984e-01,  5.5107e-02,  1.0547e-01,\n",
       "        3.7872e-01,  2.4275e-01,  1.4745e-02,  5.5951e-01,  1.2521e-01,\n",
       "       -6.7596e-01,  3.5842e-01, -4.0028e-02,  9.5949e-02, -5.0690e-01,\n",
       "       -8.5318e-02,  1.7980e-01,  3.3867e-01,  1.3230e-01,  3.1021e-01,\n",
       "        2.1878e-01,  1.6853e-01,  1.9874e-01, -5.7385e-01, -1.0649e-01,\n",
       "        2.6669e-01,  1.2838e-01, -1.2803e-01, -1.3284e-01,  1.2657e-01,\n",
       "        8.6723e-01,  9.6721e-02,  4.8306e-01,  2.1271e-01, -5.4990e-02,\n",
       "       -8.2425e-02,  2.2408e-01,  2.3975e-01, -6.2260e-02,  6.2194e-01,\n",
       "       -5.9900e-01,  4.3201e-01,  2.8143e-01,  3.3842e-02, -4.8815e-01,\n",
       "       -2.1359e-01,  2.7401e-01,  2.4095e-01,  4.5950e-01, -1.8605e-01,\n",
       "       -1.0497e+00, -9.7305e-02, -1.8908e-01, -7.0929e-01,  4.0195e-01,\n",
       "       -1.8768e-01,  5.1687e-01,  1.2520e-01,  8.4150e-01,  1.2097e-01,\n",
       "        8.8239e-02, -2.9196e-02,  1.2151e-03,  5.6825e-02, -2.7421e-01,\n",
       "        2.5564e-01,  6.9793e-02, -2.2258e-01, -3.6006e-01, -2.2402e-01,\n",
       "       -5.3699e-02,  1.2022e+00,  5.4535e-01, -5.7998e-01,  1.0905e-01,\n",
       "        4.2167e-01,  2.0662e-01,  1.2936e-01, -4.1457e-02, -6.6777e-01,\n",
       "        4.0467e-01, -1.5218e-02, -2.7640e-01, -1.5611e-01, -7.9198e-02,\n",
       "        4.0037e-02, -1.2944e-01, -2.4090e-04, -2.6785e-01, -3.8115e-01,\n",
       "       -9.7245e-01,  3.1726e-01, -4.3951e-01,  4.1934e-01,  1.8353e-01,\n",
       "       -1.5260e-01, -1.0808e-01, -1.0358e+00,  7.6217e-02,  1.6519e-01,\n",
       "        2.6526e-04,  1.6616e-01, -1.5281e-01,  1.8123e-01,  7.0274e-01,\n",
       "        5.7956e-03,  5.1664e-02, -5.9745e-02, -2.7551e-01, -3.9049e-01,\n",
       "        6.1132e-02,  5.5430e-01, -8.7997e-02, -4.1681e-01,  3.2826e-01,\n",
       "       -5.2549e-01, -4.4288e-01,  8.2183e-03,  2.4486e-01, -2.2982e-01,\n",
       "       -3.4981e-01,  2.6894e-01,  3.9166e-01, -4.1904e-01,  1.6191e-01,\n",
       "       -2.6263e+00,  6.4134e-01,  3.9743e-01, -1.2868e-01, -3.1946e-01,\n",
       "       -2.5633e-01, -1.2220e-01,  3.2275e-01, -7.9933e-02, -1.5348e-01,\n",
       "        3.1505e-01,  3.0591e-01,  2.6012e-01,  1.8553e-01, -2.4043e-01,\n",
       "        4.2886e-02,  4.0622e-01, -2.4256e-01,  6.3870e-01,  6.9983e-01,\n",
       "       -1.4043e-01,  2.5209e-01,  4.8984e-01, -6.1067e-02, -3.6766e-01,\n",
       "       -5.5089e-01, -3.8265e-01, -2.0843e-01,  2.2832e-01,  5.1218e-01,\n",
       "        2.7868e-01,  4.7652e-01,  4.7951e-02, -3.4008e-01, -3.2873e-01,\n",
       "       -4.1967e-01, -7.5499e-02, -3.8954e-01, -2.9622e-02, -3.4070e-01,\n",
       "        2.2170e-01, -6.2856e-02, -5.1903e-01, -3.7774e-01, -4.3477e-03,\n",
       "       -5.8301e-01, -8.7546e-02, -2.3929e-01, -2.4711e-01, -2.5887e-01,\n",
       "       -2.9894e-01,  1.3715e-01,  2.9892e-02,  3.6544e-02, -4.9665e-01,\n",
       "       -1.8160e-01,  5.2939e-01,  2.1992e-01, -4.4514e-01,  3.7798e-01,\n",
       "       -5.7062e-01, -4.6946e-02,  8.1806e-02,  1.9279e-02,  3.3246e-01,\n",
       "       -1.4620e-01,  1.7156e-01,  3.9981e-01,  3.6217e-01,  1.2816e-01,\n",
       "        3.1644e-01,  3.7569e-01, -7.4690e-02, -4.8480e-02, -3.1401e-01,\n",
       "       -1.9286e-01, -3.1294e-01, -1.7553e-02, -1.7514e-01, -2.7587e-02,\n",
       "       -1.0000e+00,  1.8387e-01,  8.1434e-01, -1.8913e-01,  5.0999e-01,\n",
       "       -9.1960e-03, -1.9295e-03,  2.8189e-01,  2.7247e-02,  4.3409e-01,\n",
       "       -5.4967e-01, -9.7426e-02, -2.4540e-01, -1.7203e-01, -8.8650e-02,\n",
       "       -3.0298e-01, -1.3591e-01, -2.7765e-01,  3.1286e-03,  2.0556e-01,\n",
       "       -1.5772e-01, -5.2308e-01, -6.4701e-01, -3.7014e-01,  6.9393e-02,\n",
       "        1.1401e-01,  2.7594e-01, -1.3875e-01, -2.7268e-01,  6.6891e-01,\n",
       "       -5.6454e-02,  2.4017e-01, -2.6730e-01,  2.9860e-01,  1.0083e-01,\n",
       "        5.5592e-01,  3.2849e-01,  7.6858e-02,  1.5528e-01,  2.5636e-01,\n",
       "       -1.0772e-01, -1.2359e-01,  1.1827e-01, -9.9029e-02, -3.4328e-01,\n",
       "        1.1502e-01, -3.7808e-01, -3.9012e-02, -3.4593e-01, -1.9404e-01,\n",
       "       -3.3580e-01, -6.2334e-02,  2.8919e-01,  2.8032e-01, -5.3741e-01,\n",
       "        6.2794e-01,  5.6955e-02,  6.2147e-01, -2.5282e-01,  4.1670e-01,\n",
       "       -1.0108e-02, -2.5434e-01,  4.0003e-01,  4.2432e-01,  2.2672e-01,\n",
       "        1.7553e-01,  2.3049e-01,  2.8323e-01,  1.3882e-01,  3.1218e-03,\n",
       "        1.7057e-01,  3.6685e-01,  2.5247e-03, -6.4009e-01, -2.9765e-01,\n",
       "        7.8943e-01,  3.3168e-01, -1.1966e+00, -4.7156e-02,  5.3175e-01],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc3[3].vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80168545"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1[3].similarity(doc2[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24327643"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1[3].similarity(doc3[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9681672529980867"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1.similarity(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8753348768953094"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1.similarity(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5484653936168645"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1.similarity(doc4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('Apple is looking at buying U.K. startup for $1 billion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Apple, U.K., $1 billion)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple -> ORG\n",
      "U.K. -> GPE\n",
      "$1 billion -> MONEY\n"
     ]
    }
   ],
   "source": [
    "for e in doc.ents:\n",
    "    print(e, '->', e.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=100))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile accepts the optimizer and the loss function\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "data = np.random.random((1000, 100)).astype(np.float32)\n",
    "labels = np.random.randint(2, size=(1000, 1)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 100)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0888392 , 0.52575684, 0.10466124, 0.096262  , 0.76197904,\n",
       "        0.258842  , 0.63712853, 0.6515475 , 0.75484097, 0.84816116,\n",
       "        0.6647068 , 0.91870683, 0.04878277, 0.13528776, 0.9946589 ,\n",
       "        0.4604639 , 0.36947763, 0.196974  , 0.3097918 , 0.36896285,\n",
       "        0.7101364 , 0.6462675 , 0.4810477 , 0.753921  , 0.03047181,\n",
       "        0.2926624 , 0.03936019, 0.8873632 , 0.17017573, 0.71794784,\n",
       "        0.95668125, 0.00934531, 0.46481675, 0.73416185, 0.11787887,\n",
       "        0.34529576, 0.8840936 , 0.18120424, 0.7227192 , 0.7121059 ,\n",
       "        0.2659569 , 0.86615205, 0.80185765, 0.71790755, 0.99298185,\n",
       "        0.1982901 , 0.64232624, 0.29049882, 0.49908778, 0.5950033 ,\n",
       "        0.42488784, 0.9648391 , 0.4178199 , 0.70975584, 0.16018994,\n",
       "        0.69761485, 0.1611004 , 0.35617313, 0.8770781 , 0.9502502 ,\n",
       "        0.30667582, 0.63330185, 0.53394866, 0.8001217 , 0.7815321 ,\n",
       "        0.1878482 , 0.6871309 , 0.04023051, 0.95712036, 0.46058342,\n",
       "        0.92053294, 0.8512616 , 0.06702872, 0.85360605, 0.28098783,\n",
       "        0.18938726, 0.19749293, 0.8678502 , 0.9286143 , 0.29026026,\n",
       "        0.2869731 , 0.27542827, 0.40222773, 0.06344748, 0.082164  ,\n",
       "        0.82821786, 0.91413903, 0.17342064, 0.22417483, 0.03924868,\n",
       "        0.88422656, 0.4481774 , 0.7855454 , 0.3491819 , 0.4003117 ,\n",
       "        0.23879819, 0.33158782, 0.7990248 , 0.6880956 , 0.41771564]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:3 :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.]], dtype=float32)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.7054 - acc: 0.5040\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 102us/step - loss: 0.6949 - acc: 0.5220\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 128us/step - loss: 0.6868 - acc: 0.5550\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 100us/step - loss: 0.6821 - acc: 0.5530\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 91us/step - loss: 0.6780 - acc: 0.5680\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 78us/step - loss: 0.6747 - acc: 0.5690\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 72us/step - loss: 0.6711 - acc: 0.5950\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 79us/step - loss: 0.6684 - acc: 0.6040\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 100us/step - loss: 0.6628 - acc: 0.6140\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 128us/step - loss: 0.6583 - acc: 0.6250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f99af0e82b0>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(data, labels, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant(3.0, dtype=tf.float32)\n",
    "b = tf.constant(4.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Const_10:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3.0, 4.0]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run([a,b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'add_2:0' shape=() dtype=float32>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(adder, {a: 3, b:4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30.0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(adder, {a: 10, b:20})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The same model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(tf.float32, shape=(None, 100))\n",
    "targets = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "\n",
    "fc1 = tf.layers.dense(inputs, 32, activation=tf.nn.relu)\n",
    "outputs = tf.layers.dense(fc1, 1, activation=None)\n",
    "\n",
    "outputs_sigmoid = tf.nn.sigmoid(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Placeholder_14:0' shape=(?, 100) dtype=float32>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_12/Relu:0' shape=(?, 32) dtype=float32>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_13/BiasAdd:0' shape=(?, 1) dtype=float32>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.losses.sigmoid_cross_entropy(targets, outputs)\n",
    "accuracy = tf.reduce_mean(tf.to_float(tf.equal(targets, tf.to_float(outputs_sigmoid > 0.5))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(0.001)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.725, accuracy: 0.471\n",
      "Epoch: 1, loss: 0.682, accuracy: 0.509\n",
      "Epoch: 2, loss: 0.693, accuracy: 0.528\n",
      "Epoch: 3, loss: 0.683, accuracy: 0.546\n",
      "Epoch: 4, loss: 0.683, accuracy: 0.557\n",
      "Epoch: 5, loss: 0.678, accuracy: 0.566\n",
      "Epoch: 6, loss: 0.678, accuracy: 0.578\n",
      "Epoch: 7, loss: 0.675, accuracy: 0.582\n",
      "Epoch: 8, loss: 0.674, accuracy: 0.584\n",
      "Epoch: 9, loss: 0.671, accuracy: 0.593\n",
      "Epoch: 10, loss: 0.669, accuracy: 0.599\n",
      "Epoch: 11, loss: 0.668, accuracy: 0.602\n",
      "Epoch: 12, loss: 0.665, accuracy: 0.614\n",
      "Epoch: 13, loss: 0.663, accuracy: 0.607\n",
      "Epoch: 14, loss: 0.661, accuracy: 0.615\n",
      "Epoch: 15, loss: 0.660, accuracy: 0.624\n",
      "Epoch: 16, loss: 0.657, accuracy: 0.632\n",
      "Epoch: 17, loss: 0.656, accuracy: 0.639\n",
      "Epoch: 18, loss: 0.654, accuracy: 0.643\n",
      "Epoch: 19, loss: 0.652, accuracy: 0.657\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "batch_size = 64\n",
    "nb_batches = len(data) // batch_size\n",
    "for epoch in range(nb_epochs):\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    for batch_idx in range(nb_batches):\n",
    "        batch_start = batch_idx * batch_size\n",
    "        batch_end = batch_start + batch_size\n",
    "\n",
    "        batch_inputs = data[batch_start:batch_end]\n",
    "        batch_targets = labels[batch_start:batch_end]       \n",
    "      \n",
    "        _, loss_value, accuracy_value = sess.run(\n",
    "            [train, loss, accuracy], {inputs: batch_inputs, targets: batch_targets}\n",
    "        )\n",
    "        losses.append(loss_value)        \n",
    "        accuracies.append(accuracy_value)\n",
    "        \n",
    "    accuracy_value = np.mean(accuracies)\n",
    "    loss_value = np.mean(loss_value)    \n",
    "    print(f'Epoch: {epoch}, loss: {loss_value:.3f}, accuracy: {accuracy_value:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there's also a `tf.estimator` API that makes the training a little bit simplier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       "[torch.FloatTensor of size 5]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = a + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 11\n",
       " 11\n",
       " 11\n",
       " 11\n",
       " 11\n",
       "[torch.FloatTensor of size 5]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The same model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(100, hidden_size)\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        hidden = F.relu(self.fc1(inputs))\n",
    "        outputs = self.fc2(hidden)\n",
    "        \n",
    "        outputs = outputs\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(input_size=data.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=100, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-0.0417\n",
       "-0.1653\n",
       " 0.0369\n",
       "-0.0224\n",
       "[torch.FloatTensor of size (4,1)]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(Variable(torch.rand(4, 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torch.utils.data.TensorDataset(torch.from_numpy(data), torch.from_numpy(labels))\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0888\n",
       " 0.5258\n",
       " 0.1047\n",
       " 0.0963\n",
       " 0.7620\n",
       " 0.2588\n",
       " 0.6371\n",
       " 0.6515\n",
       " 0.7548\n",
       " 0.8482\n",
       "[torch.FloatTensor of size 10]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.BCEWithLogitsLoss().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 0.696, accuracy: 0.493\n",
      "Epoch: 1, loss: 0.695, accuracy: 0.513\n",
      "Epoch: 2, loss: 0.690, accuracy: 0.553\n",
      "Epoch: 3, loss: 0.688, accuracy: 0.562\n",
      "Epoch: 4, loss: 0.687, accuracy: 0.580\n",
      "Epoch: 5, loss: 0.687, accuracy: 0.529\n",
      "Epoch: 6, loss: 0.685, accuracy: 0.564\n",
      "Epoch: 7, loss: 0.685, accuracy: 0.523\n",
      "Epoch: 8, loss: 0.684, accuracy: 0.560\n",
      "Epoch: 9, loss: 0.679, accuracy: 0.600\n",
      "Epoch: 10, loss: 0.677, accuracy: 0.589\n",
      "Epoch: 11, loss: 0.675, accuracy: 0.624\n",
      "Epoch: 12, loss: 0.672, accuracy: 0.623\n",
      "Epoch: 13, loss: 0.669, accuracy: 0.642\n",
      "Epoch: 14, loss: 0.667, accuracy: 0.636\n",
      "Epoch: 15, loss: 0.665, accuracy: 0.648\n",
      "Epoch: 16, loss: 0.662, accuracy: 0.650\n",
      "Epoch: 17, loss: 0.658, accuracy: 0.645\n",
      "Epoch: 18, loss: 0.656, accuracy: 0.647\n",
      "Epoch: 19, loss: 0.655, accuracy: 0.642\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "batch_size = 64\n",
    "nb_batches = len(data) // batch_size\n",
    "for epoch in range(nb_epochs):\n",
    "    accuracies = []\n",
    "    losses = []\n",
    "    for i, (inputs, targets) in enumerate(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        inputs = Variable(inputs).cuda()\n",
    "        targets = Variable(targets).cuda()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "\n",
    "        y_pred = (F.sigmoid(outputs) > 0.5).data.cpu().numpy()\n",
    "        y_true = targets.data.cpu().numpy()\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        \n",
    "        losses.append(float(loss))\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "    accuracy = np.mean(accuracies)\n",
    "    loss = np.mean(losses)    \n",
    "    print(f'Epoch: {epoch}, loss: {loss:.3f}, accuracy: {accuracy:.3f}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
